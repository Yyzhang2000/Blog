<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuyang Zhang">
<meta name="dcterms.date" content="2025-04-25">
<meta name="description" content="In this blog, I am going to summary the 6 most common generative models: Auto-Regreesive Model, Variational AutoEncoder, Engery Based Model, Flow Model and Diffusion Model. I will also display the pros and cons between different models, and how we can combine those models to get better performance">

<title>What a Generative Models?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../.././style/icon.avif" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-0626ff4d7a71b55c8707dcae1d04a9b6.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-e25cc82807363e79c52e96bc8b7855f1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-fc623632ca7f8a7e3590b46e839d93d9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-42a7260ea70c24697c970e75c4d4871b.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../../../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../style/styles.css">
<meta property="og:title" content="What a Generative Models?">
<meta property="og:description" content="In this blog, I am going to summary the 6 most common generative models: Auto-Regreesive Model, Variational AutoEncoder, Engery Based Model, Flow Model and Diffusion Model. I will also display the pros and cons between different models, and how we can combine those models to get better performance">
<meta property="og:image" content="images/genAI.png">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Yyzhang2000"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhang-yuyang/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#what-is-the-generative-models-and-generative-ai" id="toc-what-is-the-generative-models-and-generative-ai" class="nav-link active" data-scroll-target="#what-is-the-generative-models-and-generative-ai">What is the Generative Models and Generative AI?</a></li>
  <li><a href="#maximum-likelihood-learning" id="toc-maximum-likelihood-learning" class="nav-link" data-scroll-target="#maximum-likelihood-learning">Maximum Likelihood Learning</a></li>
  <li><a href="#auto-regressive-models" id="toc-auto-regressive-models" class="nav-link" data-scroll-target="#auto-regressive-models">Auto-Regressive Models</a></li>
  <li><a href="#variational-autoencoder-models" id="toc-variational-autoencoder-models" class="nav-link" data-scroll-target="#variational-autoencoder-models">Variational AutoEncoder Models</a>
  <ul class="collapse">
  <li><a href="#reparameterization-trick" id="toc-reparameterization-trick" class="nav-link" data-scroll-target="#reparameterization-trick">Reparameterization trick</a></li>
  </ul></li>
  <li><a href="#generative-adversarial-networks" id="toc-generative-adversarial-networks" class="nav-link" data-scroll-target="#generative-adversarial-networks">Generative Adversarial Networks</a></li>
  <li><a href="#energy-based-models" id="toc-energy-based-models" class="nav-link" data-scroll-target="#energy-based-models">Energy-Based Models</a></li>
  <li><a href="#flow-based-models" id="toc-flow-based-models" class="nav-link" data-scroll-target="#flow-based-models">Flow-Based Models</a></li>
  <li><a href="#diffusion-models" id="toc-diffusion-models" class="nav-link" data-scroll-target="#diffusion-models">Diffusion Models</a></li>
  <li><a href="#combining-different-models" id="toc-combining-different-models" class="nav-link" data-scroll-target="#combining-different-models">Combining Different Models</a>
  <ul class="collapse">
  <li><a href="#diffusion-models-vae" id="toc-diffusion-models-vae" class="nav-link" data-scroll-target="#diffusion-models-vae">Diffusion Models + VAE</a></li>
  <li><a href="#auto-regressive-vae" id="toc-auto-regressive-vae" class="nav-link" data-scroll-target="#auto-regressive-vae">Auto-Regressive + VAE</a></li>
  <li><a href="#auto-regressive-flow-models" id="toc-auto-regressive-flow-models" class="nav-link" data-scroll-target="#auto-regressive-flow-models">Auto-Regressive + Flow Models</a></li>
  <li><a href="#flow-model-vae" id="toc-flow-model-vae" class="nav-link" data-scroll-target="#flow-model-vae">Flow Model + VAE</a></li>
  <li><a href="#flow-model-gan" id="toc-flow-model-gan" class="nav-link" data-scroll-target="#flow-model-gan">Flow Model + GAN</a></li>
  <li><a href="#vae-gan" id="toc-vae-gan" class="nav-link" data-scroll-target="#vae-gan">VAE + GAN</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>What a Generative Models?</strong></h1>
  <div class="quarto-categories">
    <div class="quarto-category">Generative Model</div>
    <div class="quarto-category">Overview</div>
  </div>
  </div>

<div>
  <div class="description">
    In this blog, I am going to summary the <em>6</em> most common generative models: Auto-Regreesive Model, Variational AutoEncoder, Engery Based Model, Flow Model and Diffusion Model. I will also display the pros and cons between different models, and how we can combine those models to get better performance
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yuyang Zhang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025-04-25</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Last modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">2025-04-08</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="what-is-the-generative-models-and-generative-ai" class="level1">
<h1>What is the Generative Models and Generative AI?</h1>
<p>Generative models, as the name indicated, are models that can <em>generative</em> new content. Unlike <strong>discriminate models</strong>, the generative models are sometime hard to train. But why we need generative models in the first place? We want generative models because:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Density_estimation">Density Estimation</a>: Estimate the probability density function of the data.</li>
<li><a href="https://en.wikipedia.org/wiki/Anomaly_detection">Anomaly Detection</a>: Detect the anomaly data points.</li>
<li><a href="https://en.wikipedia.org/wiki/Imputation">Imputation</a>: Fill in the missing data.</li>
<li><a href="https://en.wikipedia.org/wiki/Data_augmentation">Data Augmentation</a>: Generate new data to increase the size of the dataset.</li>
<li><a href="https://en.wikipedia.org/wiki/Data_generation">Data Generation</a>: Generate new data to train the model.</li>
<li><a href="https://en.wikipedia.org/wiki/Data_compression">Data Compression</a>: Compress the data to save the storage.</li>
<li><a href="https://en.wikipedia.org/wiki/Denoising">Data Denoising</a>: Remove the noise from the data.</li>
<li><a href="https://en.wikipedia.org/wiki/Latent_space">Latent Space Exploration</a>: Explore the latent space of the data.</li>
<li><a href="https://en.wikipedia.org/wiki/Interpolation">Latent Space Interpolation</a>: Interpolate between the data points.</li>
</ul>
<div id="fig-overview-generative-models" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-overview-generative-models-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/202503062129654.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-overview-generative-models-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Summary of various kinds of deep generative models. (Image Source: Probabilistic Machine Learning)
</figcaption>
</figure>
</div>
<p>Generative Models can solve <strong>inverse problems</strong>. For example, the medical image reconstruction. Herea re some example of the generative models in the real world:</p>
<ul>
<li>Text to Image Model: this is common in the current AI, for example, the Stable Diffusion Model and Dalles model, below are the example of the generation of Chat-4o model:</li>
</ul>
<div id="fig-text2img-wine-glass" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-text2img-wine-glass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/paste-5.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-text2img-wine-glass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Image Generation through ChatGPT-4o model.
</figcaption>
</figure>
</div>
<ul>
<li>Text to Video model such as Sora.</li>
</ul>
<div id="fig-cern" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cern-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="images/sora-generation.mp4"></video></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-cern-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3
</figcaption>
</figure>
</div>
<p>In the blog, we will learn three things:</p>
<ul>
<li>Representation: how to model the joint distribution of many random variables</li>
<li>Learning: how to learn and compare the different probability distribution</li>
<li>Inference: how to invert the generation process ( recover high-level description (latent variables) from raw data(images, text…)</li>
</ul>
<p>Besides the three main topics, we will introduce 6 different generative models as showed in the <a href="#fig-overview-generative-models" class="quarto-xref">Figure&nbsp;1</a>. In this article, we will go through those 6 different types. Get into the details of each different types and compare models. How to combine those model to get more complex modeling ability.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this blog, we only going through the <em>main ideas</em> of the different models, if you want to dig into different topics more deeply, please check my following blogs:</p>
<ul>
<li><a href="https://yyzhang2000.github.io/Blog/posts/Generative%20Model/VAE.html">Variational AutoEncoder Models</a></li>
<li><a href="https://yyzhang2000.github.io/Blog/posts/Generative%20Model/Diffusion%20Model.html">Diffusion Models</a></li>
<li>Auto-Regressive Models (Coming soon…)</li>
<li>Flow Matching(Coming soon…)</li>
<li>GAN(Coming soon…)</li>
</ul>
</div>
</div>
</section>
<section id="maximum-likelihood-learning" class="level1">
<h1>Maximum Likelihood Learning</h1>
<div id="fig-mle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/202504082033591.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Compare modelled distribution with true distribution (Image Source: Stanford CS236 Deep Generative)
</figcaption>
</figure>
</div>
<p>The purpose of the most generative models is to learn the probability distribution <span class="math inline">\(P_\theta\)</span> that is close to the true distribution <span class="math inline">\(P_\text{data}\)</span> which we don’t know. There are different form of the <span class="math inline">\(P_\theta\)</span>, how do we choose the “best” model to represent the <span class="math inline">\(P_\text{data}\)</span>. We can use the Kullback-Leibler divergence (KL-divergence) between two distribution to measure how different those two distributions are. The KL-Divergence is defined as:</p>
<p><span id="eq-kl-divergence"><span class="math display">\[
\begin{split}D_{KL} (P\| Q ) &amp; = \mathbb{E}_{P}\left[ \log \frac{P(x)}{Q(x)} \right]  \\&amp; = \mathbb{E}_{P}[\log P(x)] - \mathbb{E}_{P}[\log Q(x)]\end{split}
\tag{1}\]</span></span></p>
<p>Two of the good property of the KL-Divergence are:</p>
<ul>
<li><span class="math inline">\(D_{KL} \geq 0\)</span>: when <span class="math inline">\(Q = P\)</span> we can get the equal</li>
<li><span class="math inline">\(\mathbb{E}_{P}\left[ - \log \frac{Q}{P} \right] \geq -\log \mathbb{E}_{P}\left[ \frac{Q}{P} \right]\)</span>: due to the<a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s inequality</a> and <span class="math inline">\(-\log\)</span> is the convex function.</li>
</ul>
<p>So, we can measure how the <span class="math inline">\(P_{\text{data}}\)</span> and <span class="math inline">\(P_{\theta}\)</span> are different:</p>
<p><span id="eq-kl-of-two-model-and-true"><span class="math display">\[
\begin{split}D_{KL}(P_{\text{data}} \| P_{\theta}) &amp; = \mathbb{E}_{x \sim P_{\text{data}}} \left[ \log \frac{P_{data}(x)}{P_{\theta}(x)} \right] \\ &amp;=   \mathbb{E}_{x \sim P_{\text{data}}} [\log P_{\text{data}}(x)] - \textcolor{green}{\mathbb{E}_{x \sim P_{\text{data}}} [\log P_{\theta}(x)]}\\\end{split}
\tag{2}\]</span></span></p>
<p>As we can see, the first term is not related to the <span class="math inline">\(\theta\)</span>, which means const across all the models and we don’t know the value. We only need to <strong>maximizing</strong> the <span class="math inline">\(\textcolor{green}{\mathbb{E}_{x \sim P_{\text{data}}} [\log P_{\theta}(x)]}\)</span> in order to minimizing the <span class="math inline">\(D_{KL}\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Notes that, although we can compare models, we are still not know how close we are to the true distribution <span class="math inline">\(P_{\text{data}}\)</span>.</p>
</div>
</div>
<p>How to calculate <span class="math inline">\(\mathbb{E}_{x \sim P_{\text{data}}} [\log P_{\theta}(x)]\)</span>, one way is to <u>approximate the expected log-likelihood with empirical log-likelihood</u>: <span class="math display">\[
\mathbb{E}_{x \sim P_{\text{data}}} [\log P_{\theta}(x)] \approx \mathbb{E}_{\mathcal{D}}[\log P_{\theta}(x)]  
= \frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} \log P_{\theta}(x)
\]</span></p>
<p>So, the maximum likelihood learning become: <span class="math display">\[
\underset{P_{\theta}}{\max}  \frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} \log P_{\theta}(x)
\]</span></p>
<p>The maximum of the likelihood function is equal to minimizing the <strong>negative log-likelihood(NLL)</strong>: <span class="math display">\[
\underset{P_{\theta}}{\max}  \frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} \log P_{\theta}(x)   
\quad \Longleftrightarrow \quad
\underset{P_{\theta}}{\min} \frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} -\log P_{\theta}(x)
\]</span> So, the loss function is: <span class="math display">\[
\mathcal{L}(\theta) = \frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} -\log P_{\theta}(x)
\]</span></p>
<p>Depending on what form&nbsp; <span class="math inline">\(p_\theta(x)\)</span>&nbsp; takes, this NLL simplifies into familiar losses like <strong>MSE</strong> or <strong>CrossEntropy</strong>.</p>
<p>When translating the above mathematical formulation into code, we commonly used some form:</p>
<ul>
<li>Mean Squared Loss (MSE): Diffusion Models</li>
<li>Cross-Entropy Loss: GAN(Binary Cross Entropy)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why we can convert MLE to loss fucn
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Assume the model outputs the <strong>mean</strong> of a Gaussian distribution: <span class="math display">\[p_\theta(x) = \mathcal{N}(x; \mu_\theta, \sigma^2 I)\]</span> Then the log-likelihood is: <span class="math display">\[\log p_\theta(x) = -\frac{1}{2\sigma^2} \|x - \mu_\theta\|^2 + \text{const}\]</span> So the <strong>negative log-likelihood</strong> becomes: <span class="math display">\[-\log p_\theta(x) = \frac{1}{2\sigma^2} \|x - \mu_\theta\|^2 + \text{const}\]</span></p>
<p>One of the problem with the MLE is that, it can easily overfit the data, that means it might not generalize well on the un-seen data set. There are several way to avoid the overfitting:</p>
<ul>
<li>Hard Constraints: limit the choice of the NN</li>
<li>Soft preference for “Simpler” Models</li>
<li>Augment the objective function with regularization</li>
</ul>
<p><span class="math display">\[
\text{obj}(x, \mathcal{M}) = \text{loss}(x, \mathcal{M}) + R(\mathcal{M})
\]</span></p>
<ul>
<li>Evaluate generalization performance on a held-out validation set.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="auto-regressive-models" class="level1">
<h1>Auto-Regressive Models</h1>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://miro.medium.com/v2/resize:fit:315/1*PLsOLk_kmYwW59UeYhegqA.png" width="480" height="494" class="figure-img"></p>
<figcaption>Auto-Regressive Model of Language Model</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://sergeiturukin.com/assets/2017-02-22-183010_479x494_scrot.png" class="img-fluid figure-img" width="480"></p>
<figcaption>PixelCNN for the Image Modeling</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="thm-ar" class="theorem-unnumbered theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Auto Regressive Model)</strong></span> An <strong>auto-regressive generative model</strong> is a type of <strong>generative model</strong> that models the <strong>joint probability distribution</strong> of a sequence (e.g., words, pixels, audio samples) by factorizing it into a <strong>product of conditional probabilities</strong>—each conditioned on the previous elements Mathematically, given a sequence <span class="math inline">\(x = (x_1, x_2, \cdots, x_T)\)</span>, the joint probability is modeled as <span class="math display">\[
P_\theta(\mathrm{x}) = \prod_{t=1}^T P_\theta(x_t | x_{&lt;t})
\]</span></p>
</div>
<p>For more details, please check my this <a href="">blog</a></p>
</section>
<section id="variational-autoencoder-models" class="level1">
<h1>Variational AutoEncoder Models</h1>
<p>For more details, please check my this <a href="https://yyzhang2000.github.io/Blog/posts/Generative%20Model/VAE.html">blog</a></p>
<div id="thm-vae" class="theorem-unnumbered theorem">
<p><span class="theorem-title"><strong>Theorem 2 (VAE)</strong></span> A VAE aims to model a generative process for data <span class="math inline">\(x\)</span> by introducing latent variables <span class="math inline">\(z\)</span>. The key idea involves optimizing the <strong>Evidence Lower Bound (ELBO)</strong>:</p>
<p><span class="math display">\[
\mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - D_{\text{KL}}\left[q_{\phi}(z|x) \| p(z)\right]
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(p_\theta(x | z)\)</span> is the decoder network parameterized by <span class="math inline">\(\theta\)</span>, often modeled as <span class="math inline">\(p_\theta(x | z) = \mathcal{N}(x; \mu_\theta(z), \sigma^2I)\)</span></li>
<li><span class="math inline">\(q_\phi(z|x)\)</span> is the approximated distribution for the true posterior <span class="math inline">\(p(z|x)\)</span>, this is the encoder part, modeled as: <span class="math inline">\(q_\phi(z | x) = \mathcal{N}(z; \mu_\phi(x), \sigma_\phi^2(x))\)</span></li>
</ul>
<p>Thus the training objective for the VAE is:</p>
<p><span class="math display">\[
\max_{\theta, \phi}\; \mathbb{E}_{x \sim p_{\text{data}}(x)}[\mathcal{L}(\theta, \phi; x)]
\]</span></p>
</div>
<p><a href="https://mlarchive.com/wp-content/uploads/2022/09/New-Project-3.png" class="uri">https://mlarchive.com/wp-content/uploads/2022/09/New-Project-3.png</a></p>
<p>The VAE model we are going to introduce is the Variational AutoEncoder. The original VAE objective (ELBO) is derived from MLE.</p>
<p><span class="math display">\[
\begin{split}\log p(x) &amp;= \log \int p(x, z) \, dz \\&amp;= \log  \int \textcolor{green}{\frac{q(z|x)}{q(z|x)}} p(x, z) \, dz  \\&amp;=  \log \mathbb{E}_{\textcolor{green}{q(z|x)}}\left[ \frac{p(x,z)}{\textcolor{green}{q(z|x)}} \right] \\ &amp;\geq  \mathbb{E}_{\textcolor{green}{q(z|x)}}\left[ \log \frac{p(x,z)}{\textcolor{green}{q(z|x)}} \right]  &amp;&amp; \text{(Jensen's Inequality)}\\ &amp; =\underbrace{ \mathbb{E}_{\textcolor{green}{q(z|x)}}[\log p(x, z) -  \log\textcolor{green}{q(z|x)}] }_{ ELBO } \\&amp;=  \mathbb{E}_{\textcolor{green}{q(z|x)}}[\log p(x |z) +\log p(z) - \log (\textcolor{green}{q(z |x)})] \\ &amp;=  \mathbb{E}_{\textcolor{green}{q(z|x)}}[\log p(x|z)]   - \mathbb{E}_{\textcolor{green}{q(z|x)}}\left[ \log \frac{\textcolor{green}{q(z|x)}}{p(x)} \right] \\ &amp;=  \mathbb{E}_{\textcolor{green}{q(z|x)}}[\log p(x|z)]  - D_{KL}(\textcolor{green}{q(z |x)} \| p(z)  ) \\\end{split}
\]</span></p>
<p>Since the <span class="math inline">\(\textcolor{green}{q(z|x)}\)</span> is intractable because of the high dimension, we use another function to <em>approximate</em> it. Same for the <span class="math inline">\(p(x | z)\)</span>. So, the MLE object become:</p>
<p><span class="math display">\[
\begin{align} &amp;\max \quad  \mathbb{E}_{\textcolor{green}{q(z|x)}}[\log p(x|z)]  - D_{KL}(\textcolor{green}{q(z |x)} \| p(z)  )  \\  \implies &amp;\min_{\theta,\phi} \quad -\mathbb{E}{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] + D_{\text{KL}}(q_{\phi}(z|x)\|p(z))\end{align}
\]</span></p>
<p>The <span class="math inline">\(p(z)\)</span> is the prior distribution of latent variable is usually as MultiVariate Gaussian Distribution. However, we can set more fancy and complex distribution as the prior distribution.</p>
<p>There are several tricks used during the training of VAE, the first one is the reparameterization tirck.</p>
<section id="reparameterization-trick" class="level2">
<h2 class="anchored" data-anchor-id="reparameterization-trick">Reparameterization trick</h2>
<p>We can use the Monte Carlo Method to evaluate the ELBO <span class="math display">\[
\quad -\mathbb{E}{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] + D_{\text{KL}}(q_{\phi}(z|x)\|p(z)) \approx \log p_{\theta}(x | z_{1})z_{1} + \text{Const}
\]</span> However, the <span class="math inline">\(z_{1}\)</span> is sampled from the a Gaussian Distribution with <span class="math inline">\(\mu, \sigma\)</span> calculated from <span class="math inline">\(q_{\phi}(z |x)\)</span>, which mean the gradient information which used to update the parameters cannot flow through this node because of the randomness. Is there are other way to remove the randomness from the loss function? This, that’s reparameterization trick do. Instead of sampling <span class="math inline">\(z\)</span> from <span class="math inline">\(q_{\phi}(z |x)\)</span>, we:</p>
<ol type="1">
<li>Sample <span class="math inline">\(\epsilon\)</span> from a fixed, parameter-free distribution (e.g.&nbsp;Normal Distribution)</li>
<li>Use a deterministic function of that sample and the parameters to get <span class="math inline">\(z = f(\epsilon)\)</span></li>
</ol>
<p><img src="https://dilithjay.com/assets/images/reparam-trick.png" class="img-fluid"></p>
<p>So the model become</p>
<p><img src="https://dilithjay.com/assets/images/vae-reparam.png" class="img-fluid"></p>
</section>
</section>
<section id="generative-adversarial-networks" class="level1">
<h1>Generative Adversarial Networks</h1>
<p>GANs are generative models that consist of two neural networks - a generator <span class="math inline">\(G\)</span>, and a discriminator <span class="math inline">\(D\)</span>- that complete against each other in a min-max game framework. The goal is for the generator to produce data indistinguishable from real samples, while discriminator tries to distinguish between real and fake(generated) data.</p>
<ul>
<li>Generator <span class="math inline">\(G\)</span>: Learns a mapping from random noise <span class="math inline">\(z \sim p_z(z)\)</span> (typically <span class="math inline">\(z \sim \mathcal{N}(0, I)\)</span> to realistic data sample <span class="math inline">\(x\)</span>: <span class="math inline">\(G(z; \theta_g) : z \mapsto x_{\text{fake}}\)</span></li>
<li>Discriminator( <span class="math inline">\(D\)</span>): Outputs a probability that a given samples <span class="math inline">\(x\)</span> is real (from dataset) rather than fake (from generator): <span class="math inline">\(D(x; \theta_d): x \mapsto [0,1]\)</span></li>
</ul>
<p>The training of GAN involves solving the following min-max optimization problem:</p>
<p><span class="math display">\[
\min_{G}\max_{D} V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<p>The training occurs iteratively by alternating steps:</p>
<ol type="1">
<li>Step 1 (Discriminator training): Update discriminator parameters <span class="math inline">\(\theta_d\)</span> to maximize tits objective, thus distinguishing fake from real data:</li>
</ol>
<p><span class="math display">\[
\max_{\theta_d} \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<ol start="2" type="1">
<li>Step 2(Generator training): Update generator parameters <span class="math inline">\(\theta_g\)</span> to minimize the discriminator’s success, effectively fooling it:</li>
</ol>
<p><span class="math display">\[
\min_{\theta_g} \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<p>In theory, the training process converges to a <strong>Nash Equilibrium</strong>.</p>
</section>
<section id="energy-based-models" class="level1">
<h1>Energy-Based Models</h1>
<p>So far, the generative models modeling the alternative of the probability of the dataset. In the Energy Based Models, it define probabilistic models using an energy function, assigning low energy to configurations(samples) that occur frequently (realistic data points) and high energy to unlikely configurations. An energy-based model defines the probability distribution of data <span class="math inline">\(x\)</span> using an energy function <span class="math inline">\(E_\theta[x]\)</span>:</p>
<p><span class="math display">\[
p_\theta(x) = \frac{\exp(-E_\theta(x))}{Z(\theta)}
\]</span></p>
<p>To training from EBMs, one typical is to maximizes the likelihood of observed data <span class="math inline">\(p_{\text{data}}(x)\)</span></p>
<p><span class="math display">\[
\max_\theta \mathbb{E}_{x \sim p_{\text{data}}}(x)[\log p_\theta(x)] = \max_\theta \mathbb{E}_{x \sim p_{\text{data}}}(x)[-E_\theta(x)] - \log Z(\theta)
\]</span></p>
<p>To Sampling from the Energy Based Model, we using an iterative approaches such as Markov Chain Monte Carlo(MCMC), especially Langevin Dynamics.</p>
</section>
<section id="flow-based-models" class="level1">
<h1>Flow-Based Models</h1>
<p>Flow-Based models are generative models that represent complex probability distributions through invertible transformations of simpler latent distributions. They explicitly prove tractable likelihood computation, unlike many other generative models such as GANs and VAEs.</p>
<p>Flow-based models define a generative process by applying an invertible and differentiable transformation <span class="math inline">\(f_{\theta}\)</span> (the “flow”) to a latent variable <span class="math inline">\(z\)</span>, typically sampled from a simple prior (e.g., standard Gaussian):</p>
<p>Given the invertibility of <span class="math inline">\(f_\theta\)</span> , we can express the likelihood the of observe data explicitly using the change of variables formula:</p>
<p><span class="math display">\[
p_{X}(x) = p_{Z}(f_{\theta}^{-1}(x)) \left| \det \frac{\partial f_{\theta}^{-1}(x)}{\partial x} \right|
\]</span></p>
<p>Training Objective of the Flow Model is:</p>
<p><span class="math display">\[
\max_{\theta}\; \mathbb{E}{x \sim p{\text{data}}(x)}\left[ \log p_{X}(x;\theta) \right]
\]</span></p>
<p>In practice, complex transformations are obtained by composing simpler invertible transformations <span class="math inline">\(f_{\theta}^{(1)}, f_{\theta}^{(2)}, \dots, f_{\theta}^{(K)}\)</span>:</p>
<p><span class="math display">\[
f_{\theta}(z) = f_{\theta}^{(K)} \circ f_{\theta}^{(K-1)} \circ \dots \circ f_{\theta}^{(1)}(z)
\]</span></p>
<p>The determinant of the Jacobian for composed transformations simplifies as follows:</p>
<p><span class="math display">\[
\log \left| \det \frac{\partial f_{\theta}^{-1}(x)}{\partial x} \right|
= \sum_{i=1}^{K} \log \left| \det \frac{\partial f_{\theta}^{(i)-1}(h_i)}{\partial h_i} \right|
\]</span></p>
</section>
<section id="diffusion-models" class="level1">
<h1>Diffusion Models</h1>
<p>For more details, please check my this <a href="https://yyzhang2000.github.io/Blog/posts/Generative%20Model/Diffusion%20Model.html">blog</a></p>
<p>The Diffusion Models are generative models that learn to reverse a gradual corruption process applies to data. They gained popularity due to their impressive results in generating high-quality, diverse samples across domain such as images, audio, and text. Diffusion models consist of two processes:</p>
<ul>
<li>Forward(Diffusion) Processes:</li>
</ul>
<p>Gradually adds noises to data <span class="math inline">\(x_0\)</span> over <span class="math inline">\(T\)</span> timesteps, typically Gaussian noise:</p>
<p><span class="math display">\[
q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t}x_{t-1}, \beta_t I), \quad t = 1,\dots,T
\]</span></p>
<p>This form a Markov chain. So the forward distribution can also be expressed directly in terms of <span class="math inline">\(x_0\)</span>:</p>
<p><span class="math display">\[
q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t)I)
\]</span></p>
<p>where <span class="math inline">\(\alpha_t = 1 - \beta_t, \quad \bar{\alpha}_t = \prod_{s=1}^{t}\alpha_s\)</span></p>
<ul>
<li>Reverse (Genrative) Process:</li>
</ul>
<p>The generative models learns to reverse this diffusion, gradually removing noise. It’s defined as:</p>
<p><span class="math display">\[
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\]</span></p>
<p>Diffusion models are trained by maximizing the likelihood of the observed data. However, in practice, the training often simplifies to a denoising objective:</p>
<p><span class="math display">\[
L(\theta) = \mathbb{E}{x_0, \epsilon, t}\left[ \|\epsilon - \epsilon\theta(\sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon, t)\|^2 \right]
\]</span></p>
<p>The Sampling involves starting from pure noise and gradually denoising:</p>
<p><span class="math display">\[
x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}t}}\epsilon\theta(x_t, t)\right) + \sqrt{\beta_t}\epsilon,\quad \epsilon\sim\mathcal{N}(0, I)
\]</span></p>
</section>
<section id="combining-different-models" class="level1">
<h1>Combining Different Models</h1>
<section id="diffusion-models-vae" class="level2">
<h2 class="anchored" data-anchor-id="diffusion-models-vae">Diffusion Models + VAE</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-2.png" class="img-fluid figure-img"></p>
<figcaption>The Architecture of the Stable Diffusion Models (Image Source: High-Resolution Image Synthesis with Latent Diffusion Models)</figcaption>
</figure>
</div>
<p>One limitation of the diffusion models, it need to go through many steps on the high-dimensional space. If we can train an model on the lower dimension and recover it back to the high dimension, than we can speed up both training and generating process. As proposed in <span class="citation" data-cites="rombachHighResolutionImageSynthesis2022">(<a href="#ref-rombachHighResolutionImageSynthesis2022" role="doc-biblioref">Rombach et al. 2022</a>)</span>, the Latent Diffusion Model is one of those approach. It leverages latent diffusion techniques, making it computationally efficient and capable of generating diverse, photorealistic, and detailed visuals from textual prompts. Widely adopted for its open-source accessibility, Stable Diffusion enables artists, researchers, and developers to produce remarkable content easily.</p>
</section>
<section id="auto-regressive-vae" class="level2">
<h2 class="anchored" data-anchor-id="auto-regressive-vae">Auto-Regressive + VAE</h2>
</section>
<section id="auto-regressive-flow-models" class="level2">
<h2 class="anchored" data-anchor-id="auto-regressive-flow-models">Auto-Regressive + Flow Models</h2>
</section>
<section id="flow-model-vae" class="level2">
<h2 class="anchored" data-anchor-id="flow-model-vae">Flow Model + VAE</h2>
</section>
<section id="flow-model-gan" class="level2">
<h2 class="anchored" data-anchor-id="flow-model-gan">Flow Model + GAN</h2>
</section>
<section id="vae-gan" class="level2">
<h2 class="anchored" data-anchor-id="vae-gan">VAE + GAN</h2>
<p>As metioned in the paper <span class="citation" data-cites="larsenAutoencodingPixelsUsing2016">(<a href="#ref-larsenAutoencodingPixelsUsing2016" role="doc-biblioref">Larsen et al. 2016</a>)</span></p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In the blog, we has explore go through several generative models. We explore why we need generative models. For different purposes, we can different choice of the models. On the other hand, we can combine different models to get better performance. There are still more room for the generative models.<br>
</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-larsenAutoencodingPixelsUsing2016" class="csl-entry" role="listitem">
Larsen, Anders Boesen Lindbo, Søren Kaae Sønderby, Hugo Larochelle, and Ole Winther. 2016. <span>“Autoencoding Beyond Pixels Using a Learned Similarity Metric.”</span> February 10, 2016. <a href="https://doi.org/10.48550/arXiv.1512.09300">https://doi.org/10.48550/arXiv.1512.09300</a>.
</div>
<div id="ref-rombachHighResolutionImageSynthesis2022" class="csl-entry" role="listitem">
Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022. <span>“High-<span>Resolution Image Synthesis</span> with <span>Latent Diffusion Models</span>.”</span> April 13, 2022. <a href="https://doi.org/10.48550/arXiv.2112.10752">https://doi.org/10.48550/arXiv.2112.10752</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>videojs(video_shortcode_videojs_video1);</script>




</body></html>